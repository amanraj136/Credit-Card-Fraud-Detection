\# Credit Card Fraud Detection â€” Streamlit App + Scikit-learn



<!-- Badges (add CI/CD, Streamlit, or license badges here when available) -->

<!-- \\\[!\\\[Streamlit App](https://img.shields.io/badge/Streamlit-Demo-orange)](https://streamlit.io) -->



<!-- Live demo link placeholder -->

<!-- ðŸ”— \\\*\\\*Live Demo:\\\*\\\* \\\[Add your Streamlit deployment URL here once published] -->





\## Overview



This project detects fraudulent credit card transactions using classical machine learning models trained on the \*\*Kaggle Credit Card Fraud Detection dataset\*\*.

The dataset is \*\*highly imbalanced\*\* (~0.173% fraud cases). The workflow applies \*\*StandardScaler\*\* for normalization and \*\*SMOTE\*\* for balancing during training.



Multiple algorithms were evaluated â€” \*\*Logistic Regression\*\*, \*\*Naive Bayes\*\*, \*\*Random Forest\*\*, and \*\*XGBoost\*\* â€” and the \*\*Gradient Boosting (XGBoost-based)\*\* model was selected for deployment, achieving a \*\*ROC-AUC â‰ˆ 0.979\*\* with strong recall on minority (fraud) detection under higher F-beta settings.



The Streamlit app enables:

\- \*\*Single transaction prediction\*\* via comma-separated input

\- \*\*Batch CSV upload\*\* for large-scale inference with downloadable results





\## Dataset Summary



\- \*\*Size:\*\* 284,807 transactions Ã— 31 columns

\- \*\*Columns:\*\*

Â  - \*\*Features:\*\* `Time`, `V1`, `V2`, â€¦, `V28`, `Amount`

Â  - \*\*Target:\*\* `Class` (0 = Normal, 1 = Fraud)

\- \*\*Challenge:\*\* Only ~0.173% of all transactions are fraudulent (extreme imbalance).





\## Methodology



\- \*\*Preprocessing:\*\* Standard scaling for all numeric columns

\- \*\*Imbalance Handling:\*\* SMOTE applied on training set only (to prevent data leakage)

\- \*\*Models Evaluated:\*\*

Â  - Logistic Regression â†’ ROC-AUC â‰ˆ 0.971

Â  - Naive Bayes â†’ ROC-AUC â‰ˆ 0.965

Â  - Random Forest â†’ ROC-AUC â‰ˆ 0.968

Â  - \*\*XGBoost (final)\*\* â†’ ROC-AUC â‰ˆ 0.979

\- \*\*Metrics Used:\*\*

Â  ROC-AUC, PR-AUC, F1-score, and \*\*F-beta (Î² âˆˆ {0.5, 1, 2, 3})\*\* for recallâ€“precision trade-offs

\- \*\*Chosen Model:\*\* XGBoost for strong minority recall and balanced F-beta performance





\## Key Results



\- \*\*Best Model:\*\* Gradient Boosting (XGBoost)

\- \*\*ROC-AUC:\*\* ~0.979 on test data

\- \*\*Recall (Fraud Class):\*\* Highest under F-beta > 1 emphasis

\- \*\*Trade-off:\*\* Slight precision loss for improved fraud recall

\- \*\*Figures:\*\*

Â  - `figures/class\\\_distribution.png`

Â  - `figures/temporal\\\_analysis\\\_by\\\_day.png`

Â  - `figures/confusion\\\_matrices.png`

Â  - `figures/fbeta\\\_comparison.png`

Â  - `figures/fbeta\\\_grouped\\\_comparison.png`





\## How to Run Locally

1. Python 3.10+
2. Install dependencies:

&nbsp;	pip install -r requirements.txt

3\. Ensure the model file `best\_model\_gradient\_boosting.pkl` is in the project root.

4\. Start app:

&nbsp;	Option A: Double-Click `app.bat` to launch the app in your browser.

&nbsp;	Option B: `streamlit run app.py` in the terminal.





\## Files

\- `app.py` â€” Streamlit UI and inference.

\- `app.bat` â€” Launch the app in the default browser.

\- `best\_model\_gradient\_boosting.pkl` â€” trained pkl model.

\- `dataset/` â€” use `creditcard.csv` at project root.

\- `figures/` â€” ROC/PR Curves, Confusion Matrces, Class Distribution, etc. 

\- `notebook/` â€” training notebook.

\- `test\_samples/` â€” Batch test samples in `.csv` format for downloading and testing purposes.

